\newcommand{\texCommand}[1]{\texttt{\textbackslash{#1}}}%

\newcommand{\exemplo}[1]{%
\vspace{\baselineskip}%
\noindent\fbox{\begin{minipage}{\textwidth}#1\end{minipage}}%
\\\vspace{\baselineskip}}%

\newcommand{\exemploVerbatim}[1]{%
\vspace{\baselineskip}%
\noindent\fbox{\begin{minipage}{\textwidth}%
#1\end{minipage}}%
\\\vspace{\baselineskip}}%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
A necessidade de mecanizar tarefas humanas data desde o período clássico da
civilização, em cerca de 350 a.C. na Grécia Antiga. Aristóteles, filosofo e
aluno de Platão, entre diversos escritos que produziu, investigou o homem, a
mente e a razão \cite{russell2004history}. Em seu livro \textit{Politiká}, um
trabalho de ética e filosofia política, Aristóteles descreve a necessidade de
automatizar tarefas humanas por meio de mecanismo que obedeçam ``palavras de
comando ou antecipação inteligente'' também chamados de ``tripods''
\cite{2013aristotle}, como forma de resolver problemas sociais, como a
escravidão. Não apenas neste trabalho, mas muito outros trabalhos foram
idealizadores do que futuramente se tornaria o campo de inteligência artificial
\cite{russell2016artificial}.

Embora a idealização de mecanizar tarefas tenha surgido na Grécia, uma
abordagem prática para isso já havia sido produzida muitos anos antes, em cerca
de 2500 a.C. Matemáticos babilônios com o objetivo de dividir grãos em
quantidades justas entre seus pares, desenvolvem uma série de etapas e
operações ordenadas para se seguir que ao final lhes garantiria o resultado
almejado \cite{chabert1999history}, esse foi um dos primeiros registros de um
conceito que hoje é nomeado `algoritmo'.

Com o advento da computação e a concepção da máquina universal, o termo
algoritmo foi adotado por esta ciência para designar instruções finitas e bem
definidas que podem ser implementadas em um computador para resolver classes de
problemas \cite{britannica2006algorithm}, o computador moderno tendo posse
então dessas ``palavras de comando'' irá então executar de forma autônoma até o
fim de sua execução, muito similar aos ``tripods'' idealizados por Aristóteles.

Porém, uma simples lista de comandos não seria suficiente para que esses
mecanismos autônomos conseguissem replicar a atuação humana em ambientes
desconhecidos, complexos e imprevisíveis \cite{russell2016artificial}, uma
parte fundamental da capacidade humana que permite lidar com essas lacunas é a
inteligência. Até o presente momento, não há um consenso sobre o que é ser
inteligente e muito menos o que é necessário para construir uma entidade
inteligente \cite{russell2016artificial}. Um grupo de 52 especialistas listou o
uso de ferramentas da mente como: perceber, memorizar, aprender, compreender,
imaginar, planejar e raciocinar \cite{gottfredson1997mainstream}, porém nossa
compreensão objetiva dessas ferramentas se aplica apenas a algumas, dentre elas
a que tivemos grande sucesso em simular foi o raciocínio
\cite{russell2016artificial}.

A principal divisão entre os tipos de raciocínio são duas, o método dedutivo e
o método indutivo. Matemáticos, lógicos e cientistas da computação com grande
sucesso tem conseguido desenvolver sistemas baseados no raciocínio dedutivo e
operar sobre premissas através e regras lógicas para provas ou verificar
teoremas, um exemplo disso são as linguagens \textit{Coq} e \textit{PROLOG}.
Aliado a isso, algoritmos de busca permitem deduzir soluções pela verificação
da árvore de eventos.

Porém, o método indutivo apresenta limitações quanto a sua capacidade de
descobertas. Como discutido por Hume \cite{hume2000enquiry} e Kant
\cite{smith2011immanuel} certos conhecimentos não podem ser obtidos
exclusivamente através da dedução, o juízo analítico, sendo então necessário
o uso da percepção e experimentação \cite{popper2005logic}, o juízo sintético,
logo máquinas que pretendam simular o raciocínio humano devem ter a capacidade
de desempenhar esses dois tipos de juízo, o raciocínio dedutivo, regras restritas a
partir de regras gerais, e o raciocínio indutivo, que possibilita generalizar regras
a partir de eventos singulares.

O aprendizado, uma forma geral de indução, está presente nas mais diversas formas de
vida \cite{shettleworth2001animal}, mas especialmente nos humanos, pela língua e cultura,
nos permitiu progredir em ritmos acelerados na escala de inteligência e a manipular
o ambiente a nossa volta de tal forma que possamos superar os objetivos básicos de
um ser vivo, crescer, se alimentar e reproduzir, em busca de novos de maior complexidade,
como colonizar novos planetas \cite{musk2017making}. Logo, o aprendizado se
apresenta como uma abordagem natural para nós humanos ``inserirmos'' inteligência nas
máquinas.

Na próxima seção definimos uma possível formalização para o aprendizado e motivamos como
obter isso por meios computacionais. Diferente do aprendizado estatístico como em \cite{friedman2001elements}, este trabalho será baseado nas teorias computacionais de
aprendizado como apresentadas em
\cite{valiant1984theory,gold1967language,kearns1994introduction}.

\section{Aprendizado de Máquina}
\label{sec:aprendizado-de-maquina}

No contexto de inteligência artificial, o \textbf{Aprendizado}, ou Aprendizado
de Máquina (AM), é o estudo e a concepção de agentes que melhoram o seu
desempenho nas tarefas futuras após fazer observações sobre o mundo
\cite{russell2016artificial, mohri2018foundations}. Um dos modelos mais adotados
para descrever e especificar a tarefa de aprendizado por um computador é
descrito formalmente em \cite{mitchell1997machine}, este apresenta da seguinte
forma:

\begin{definition}
Um programa de computador (agente), \textit{aprende} de uma experiência
$\boldsymbol E$ a respeito de alguma classe de tarefa $\boldsymbol T$ e medida
de performance $\boldsymbol P$, se a performance na tarefa $\boldsymbol T$,
medido por $\boldsymbol P$, melhora com a experiência $\boldsymbol E$.
\end{definition}

No modelo \textbf{supervisionado}\footnote{A literatura subdivide problemas de
aprendizado em supervisionado, não supervisionado e por reforço
\cite{russell2016artificial,friedman2001elements,goodfellow2016deep},
porém há outros paradigmas mais gerais, como a identificação de linguagem no
limite \cite{gold1967language}}, o qual lidaremos exclusivamente neste
trabalho, a experiência $\boldsymbol E$ é um registro
$\boldsymbol{x}=(x_1,x_2,...,x_n)$, em que $x_i$ é um valor real computável
($\mathbb{R}_c$), e seu respectivo rotulo $y$. A tarefa $\boldsymbol T$
consiste em atribuir um valor $\hat{y}$ para um $\boldsymbol{x}$ onde o $y$
real ainda não é conhecido, mas assumindo que esse par ordenado
$(\boldsymbol{x},y)$ será gerado por um programa desconhecido porém que
assumimos sua invariância e regularidade de aprendizagem
\cite{mohri2018foundations,valiant1984theory}.

Para isto, queremos induzir através dos pares de experiência
($\boldsymbol{x},y$) uma \textbf{função computável} $f_c$, isto é, uma máquina
de Turing (MT) que sobre a entrada $\boldsymbol{w}$ para com exatamente
$f_c(\boldsymbol{w})$ sobre sua fita, de tal forma que ao mensurarmos
observações futuras de $f_c(\boldsymbol{x})$ por $\boldsymbol P$, o valor de
$\boldsymbol{P}(\hat{y},y)$ tenda a um erro irredutível
\cite{mohri2018foundations,mitchell1997machine,friedman2001elements}.

Codificaremos $y$ em dois tipos de tarefas em $\boldsymbol{T}$, na primeira
queremos computar uma cadeia de bits que representa um valor \textbf{real
computável} a partir da entrada $\boldsymbol{x}$, ou seja, queremos uma $f_c$
tal que $f_c:\mathbb{R}_c^n\longrightarrow \mathbb{R}_c$, essa tarefa
denominamos \textbf{regressão}. Na segunda tarefa, queremos descobrir a função
$f$ que tenha como saída um único bit, de tal forma que
$f:\mathbb{R}_c^n\longrightarrow \{0,1\}$, essa tarefa denominamos
\textbf{classificação}\footnote{Embora definido para duas classes o formalismo
descrito aqui pode ser estendido para mais de duas classes com métodos
multi classe \cite{abu2012learning}.} \cite{goodfellow2016deep,
mohri2018foundations}.

O processo indutivo descrito anteriormente não é uma tarefa fácil,
para um número finitos de exemplos existem infinitas funções ($f_c$) que
interpolam perfeitamente todos esses
pontos\cite{bishop2006pattern,abu2012learning}, entretanto, para que se tenha
um bom desempenho em tarefas futuras, tal função deve se aproximar do real
programa gerador dos dados
\cite{mohri2018foundations,goodfellow2016deep,solomonoff1964formal,kearns1994introduction},
o que nos leva a pergunta: ``qual dessas funções deve ser escolhida?''

Um princípio que pode ser adotado nessa escolha, é o chamado \textit{"Navalha
de Ockham"} \cite{blumer1987occam}, ele diz que para duas hipóteses de igual
poder explicativo, é preferível escolher a \textit{mais simples}. Para o caso
da escolha entre polinômios, isto é, funções da forma
\[f(x) = a_0x^n+a_2x^{n-1}+...+a_n,\]
essa é uma tarefa fácil, já que podemos compará-los em complexidade pelo
polinômio de maior grau, porém estendendo essa tarefa para qualquer classe de
funções, essa deixa de ser uma tarefa simples.

No inicio do desenvolvimento de técnicas de inferência indutiva, não havia uma
definição formal do que seria uma hipótese ``mais simples'', em 1964 com o
trabalho de Solomonoff da teoria de inferência indutiva universal
\cite{solomonoff1964formal}, é apresentada uma definição formal para o que
seria esse principio: a MT de menor comprimento que computa tal observação,
isso é, a $f_c$ com menor complexidade de Kolmogorov. Esse sistema indutivo do
ponto de vista teórico pode ser considerado perfeito \cite{li1992inductive}, já
que assumindo que o mundo é gerado por um programa desconhecido, na
distribuição de probabilidade algorítmica, programas de menor descrição são os
mais prováveis.

Porém já se sabe que tal MT (programa) é \textbf{indecidível}, pois escolher um
programa equivalente de menor comprimento é mapeável ao problema da parada
\cite{sipser2012introduction,solomonoff1978complexity}, logo, no caso geral,
seria impossível descrever um \textbf{método efetivo} para proceder tal escolha
\cite{hutter2004universal}. Uma solução a esse problema\footnote{As teorias
Dimensão VC \cite{vapnik2013nature}, Complexidade de Rademacher
\cite{bartlett2002rademacher} e PAC \cite{valiant1984theory} são casos
restritos da inferência indutiva universal
\cite{li1992inductive,blumer1989learnability}} é definir \textit{a priori} um
espaço de hipóteses $\mathcal{H}$ (programas) de menor
cardinalidade\footnote{Também referido como Viés.}, e.g. todos os programas que
podem ser descritos em Python com no máximo $10^9$ bits, assim, algoritmos
efetivos poderiam escolher os programas de menor descrição em seu respectivo
$\mathcal{H}$ \cite{rathmanner2011philosophical}.

Embora não exista uma máquina de Turing (MT) que resolva o caso geral, a teoria
Provavelmente Aproximadamente Correto (PAC) de aprendizado nos dá garantias da
existência de máquinas que encontrem uma função aproximada em tempo polinomial,
isto é, para alguma amostra de tamanho $n$, existe uma MT que com tempo $O(n^k)$
para algum $k \in \mathbb{N}$, encontra uma MT $c$ que mapeia
$c:\mathcal{X}\rightarrow\mathcal{Y}$, de tal forma que essa MT se aproxime da
real função geradora $f_c$ com alta probabilidade. Para isso a classe de
programas geradores que se pode assumir deve ser limitada, apenas dados gerados
de forma independente por uma distribuição estacionaria nos garante a validade
das propriedades dos teoremas apresentados a seguir.

Limitamos as funções computáveis que queremos descobrir a retângulos que
classificam pontos em $\mathbb{R}^2$ , os quais pertencem aos conjunto de
conceitos $c \in \mathcal{C}$. Seja um retângulo $c$ de tal forma que $c$
classifique o ponto em 1 se contido dentro do retângulo ou 0, c.c, isto é,
$c:\mathcal{X}\rightarrow\mathcal{Y}$, sendo $\mathcal{X} \in \mathbb{R}^2$, as
coordenadas no plano cartesiano e $\mathcal{Y} \in \{0,1\}$, a classe ao qual
aquele ponto é atribuída. O algoritmo deve conter um espaço de hipóteses fixo
$\mathcal{H}$ que não necessariamente coincida com $\mathcal{C}$ e obter
amostras $S=(X_1,X_2,...,X_m)$ obtidas da distribuição $\mathcal{D}$, esta
i.i.d. (independente e identicamente distribuído) como descrito anteriormente,
junto a isso as respectivas classes ($c(X_1),c(X_2),..,c(X_m)$), isto é, está
ou não contido no retângulo.

O objetivo é então usar os exemplos em S para selecionar uma $h \in \mathcal{H}$
que tenha um baixo erro de generalização a respeito do conceito $c$. O erro de
generalização da hipótese $h$, também chamado de risco, é da por $R(h)$ da
seguinte forma,

\begin{equation}
    R(h) = \underset{x\sim\mathcal{D}}{\mathbb{P}}[h(x) \neq c(x)] = 
    \underset{x\sim\mathcal{D}}{\mathbb{E}}[1_{h(x) \neq c(x)}],
\end{equation}

onde $1_\omega$ é a função indicadora do evento $\omega$ \cite{mohri2018foundations}.

Embora o erro real não seja mensurável, já que a distribuição $\mathcal{D}$ e função
$c$ são inaccessíveis para essa máquina, podemos calcular o erro empírico. Dado a
amostra $S$ definida anteriormente, o risco empírico é calculado por 

\begin{equation}
    \Hat{R}_S(h) = \frac{1}{m} \sum_{i=1}^m 1_{h(x) \neq c(x)}.
\end{equation}
Ou seja, o erro empírico de $h$ é o erro médio na amostra $S$, porém, para um $m$
suficientemente grande e uma distribuição i.i.d, o valor esperado de $\Hat{R}$
se aproxima de $R$.

Definimos agora o aprendizado PAC. Seja $n$ um numero de tal forma que qualquer
representação de $X \in \mathcal{X}$ seja no máximo $O(n)$ e representado por
$size(c)$ o custo máximo da representação de uma $f_c$, ou seja, complexidade de
Kolmogorov de $c \in \mathcal{C}$. Por exemplo, $X$ pode ser uma sequência de bits
representando $R_c^m$, de tal forma que essa sequência tenha $O(n)$. Adicionalmente,
seja $h_S$ a hipótese obtida pela MT $\mathcal{A}$ após receber uma amostra $S$.

\begin{definition}
Uma classe de conceitos $\mathcal{C}$ é dita PAC-aprendível se existe uma MT $\mathcal{A}$
e uma função polinomial $poly(.,.,.,.)$ de tal forma para que um dado $\epsilon > 0$ e
um $\delta > 0$. para todas as distribuições $\mathcal{D}$ sobre $\mathcal{X}$ e para
qualquer conceito alvo $c \in \mathcal{C}$, o seguinte é satisfeito, para qualquer amostra
de tamanho $m \geq poly(1/\epsilon, 1/\delta, n, size(c))$: 
\begin{equation}
\underset{S\sim\mathcal{D}^m}{\mathbb{P}}[R(h_S)\leq\epsilon]\geq 1-\delta
\end{equation}
Se $\mathcal{A}$ opera em $poly(1/\epsilon, 1/\delta, n, size(c))$, então $\mathcal{C}$
é dito ser eficientemente PAC-aprendível. Quando tal MT $\mathcal{A}$ existe, é chamado um
algoritmo PAC-aprendível para $\mathcal{C}$.
\end{definition}

Logo, dizemos que uma classe de conceitos $\mathcal{C}$ é PAC-aprendível, se a hipótese
retornada pela MT aprendiz, após observar um número de pontos polinomial em relação a
$1/\epsilon$ e $1/\delta$ é aproximadamente correto, isto é, tem um erro no máximo
$\epsilon$, com alta probabilidade, pelo menos $1-\delta$. Ou seja, sendo $1-\delta$ a
confiança e $1-\epsilon$ a acurácia, é definido que $h$ terá um custo computacional
polinomial em razão desses fatores.

\textcolor{red}{falar do pac learning, np-complexidade}

Existe uma diversidade de algoritmos para seleção de hipóteses
\cite{bishop2006pattern,friedman2001elements}, neste trabalho apresentaremos a
Árvore de Decisão, e algoritmos derivados como Floresta Aleatória e Máquinas de
Reforço (\textit{Boosting}) do Gradiente, também apresentaremos as Máquinas de
Vetores de Suporte.

\subsection{Árvores de Decisão}
Árvores de Decisão são modelos que devido sua simplicidade tem fácil
interpretabilidade e podem ser combinado com técnicas de amostragem e reforço
em algoritmos em modelos muito mais poderosos. Embora exista um diversidade de
algoritmos para sua concepção nos basearemos no modelo CART proposto em
\cite{breiman1984classification}, a intuição por trás desse algoritmo é
particionar o espaço de atributos $\mathcal{X}$ em regiões em $R_i$, de
tal forma que cada $R_i$ se aproxime do valor médio de $\mathcal{Y}$ para
aquela região.

\begin{figure}[ht]
   \centering
    \begin{subfigure}{.4\textwidth}
        \centering
        \def\svgwidth{1.4\linewidth}
        \incfig{binarytree}
        \caption{Árvore de decisão com predicados booleanos sobre os atributos.}
        \label{fig:tree}
    \end{subfigure}
     \hfill
    \begin{subfigure}{.4\textwidth}
        \centering
        \def\svgwidth{.8\linewidth}
        \incfig{splitregion}
        \caption{Plano cartesiano particionado por uma árvore de decisão.}
        \label{fig:split}
    \end{subfigure}
    \caption{Exemplo de árvore de decisão}
    \label{fig:three graphs}
\end{figure}


Na Figura \ref{fig:split} é exemplificado um particionamento dado pela árvore
da Figura \ref{fig:tree}, na raiz da árvore de decisão é aplicado um predicado
booleano que irá dividir os dados em dois subconjuntos, a cada divisão nos nós
esses subconjuntos são aplicados a novos predicados gerando subconjuntos
menores.

Explicada o funcionamento das árvores, detalhamos agora como construí-las. Para
isso, é feito uma busca exaustiva em todos os atributos $j$ e seus valores
$t_m$ bi particionando os dados em $\theta = (j,t_m)$ como mostrado em
\ref{eq:splitc}.

\begin{equation}
        \begin{aligned}
            Q_{\text{left}}(\theta) = {(x, y) | x_j <= t_m}\\
            Q_{\text{right}}(\theta) = Q \setminus Q_{\text{left}}(\theta)
        \end{aligned}
    \label{eq:splitc}
\end{equation}

De tal forma a minimizar $L$ sobre a função de
impureza $H$.

\begin{equation}
    \underset{\theta}{\text{arg min}} \left[ L(\theta) =  \frac{n_{\text{left}}}{N_m} H(Q_{\text{left}}(\theta)) +
    \frac{n_{\text{right}}}{N_m} H(Q_{\text{right}}(\theta)) \right]
    \label{eq:treegreed}
\end{equation}

Para o calculo do $H$ é dado pela proporção de classes na região $R_m$,
dado $N_m$ observações, em razão do erro de classificação.

\begin{equation}
    p_{mk} = \frac{1}{N_m} \sum_{x_i \in R_m} I(y_i = k)
\end{equation}

Em \cite{friedman2001elements} são apresentados alguns dos critérios que podem
ser usados para computar a impureza da classificação, aqui aplicaremos o índice
Gini.

\begin{equation}
    H(X_m) = \sum_{k=1}^{K} \hat{p}_{mk}(1 - \hat{p}_{mk})
    \label{eq:gini}
\end{equation}

Esse particionamento é então aplicado recursivamente até que seja atingido
algum critério de regularização, por exemplo, o limite mínimo para $m$ ou
definido um valor mínimo para $H$.

Embora árvores de decisão tenha diversas vantagens, elas tendem a sobreajustar
aos dados, uma possível solução para isso é o uso de comitês.

\subsection{Floresta Aleatória (RF)}

Árvores de decisão podem ``decorar'' os dados de treino, não generalizando para
casos desconhecidos, o chamado sobreajuste. O \textit{Bagging}, uma técnica de
reamostragem, tenta diminuir esse sobreajuste por meio da diminuição da
variação entre os modelos, ou seja, modelos obtidos de forma independente
tendam a uma mesma predição. Ele consiste em designar subamostras aleatórias
(com repetição) do conjunto de dados e ao final as estimativas desses modelos
são combinadas.

Porém ainda assim, dado a natureza determinística e a flexibilidade de uma
árvore de decisão o problema do sobreajuste pode não ser resolvido, é
necessário então aleatorizar o processo de geração da árvore. O método de
subespaço aleatório (\textit{random subspace method}) provê isso limitando o
espaço de busca por bipartições da árvore, a cada novo nó da árvore que está
sendo construída, apenas um subconjunto aleatório dos atributos pode ser
escolhido para a bipartição dos dados.

\begin{algorithm}[ht]
\SetKwInput{KwInput}{Input}
\SetKwInput{KwOutput}{Output}
\KwData{Conjunto de dados $D$ com atributos $p$.}
\KwInput{$B$ - Número de estimadores a serem construídos, $m$ - Número de atributos
nos subconjuntos.}
\KwOutput{Classificador - Maioria dos votos de $\{T_b\}^B$.}
\begin{enumerate}
    \item Para $b=1$ até $B$.
    \begin{enumerate}
        \item Obtenha um subconjunto aleatório com repetição
            (\textit{Bootstrap}) de $D$.
        \item Construa uma árvore $T_b$ recursivamente da seguinte forma:
        \begin{enumerate}
            \item Selecione m variáveis do conjunto $p$.
            \item Selecione a melhor variável e bipartição em $m$.
            \item Divida o nó em dois nós filhos.
        \end{enumerate}
    \end{enumerate}
    \item Retorne o conjunto de arvores $\{T_b\}^B$.
\end{enumerate}
 \caption{Floresta Aleatória}
 \label{algo:rf}
\end{algorithm}

Essa limitação garante que as árvores de entropia máxima não possam ser sempre
geradas, diminuindo a correlação entre as árvores e, portanto, melhorando a
capacidade de generalização desse estimador. No Algoritmo \ref{algo:rf} é
apresentado o pseudo-código da Floresta Aleatória para a indução de um modelo.

\subsection{Máquina de Reforço do Gradiente}

O algoritmo de Floresta Aleatória nos dá uma ideia do poder que temos ao
combinar algoritmos simples, também chamado \textit{weak learner}, em
algoritmos mais robustos. Uma outra alternativa a combinação de modelos é o
Reforço, ou \textit{Boosting}, esse consiste em criar estimadores a partir do
resíduo de estimadores anteriores, assim esse novo estimador tem uma tarefa
mais simples e logo, quando combinado com toda a sequência de estimadores, pode
apresentar maior robustez no aprendizado.

Demonstramos anteriormente como árvores CART são induzidas, sendo $R_j,j=1,2,..J$ as regiões particionadas pela árvore, se $x \in R_j \implies f(x) = \gamma_j$, que no caso de classificação $\gamma_j$ é o valor modal daquela região. Logo podemos definir formalmente como

\begin{equation}
    T(x;\Theta) = \sum_{j=1}^J \gamma_j I(x \in R_j),
\end{equation}

sendo $\Theta = \{R_j,\gamma_j\}_1^J$ parâmetros obtidos minimizando o risco empírico dado por

\begin{equation}
    \hat{\Theta} = \underset{\Theta}{\text{arg min}}
    \sum_{i=1}^N L(y_i,T(x;\Theta)).
\end{equation}

Logo, as árvores de reforço são dadas por

\begin{equation}
\label{eq:tree_boost}
    f_M(x) = \sum_{m=1}^M T(x;\Theta_m),
\end{equation}

induzidas sequencialmente resolvendo

\begin{equation}
    \hat{\Theta}_m = \underset{\Theta_m}{\text{arg min}}
    \sum_{i=1}^N L(y_i,f_{m-1}(x_i)+T(x_i;\Theta_m)),
\end{equation}

logo, cada árvore deve aprender apenas o resíduo do erro da árvore anterior, isto é, a árvore $m$ deve predizer $y_i - f_{m-1}(x_i)$. Porém o método descrito aqui embora seja intuitivo e correto, é ineficiente, sendo preferível sua aproximação que pode ser obtida em um único passo e não sequencialmente.

Definimos a função de custo por

\begin{equation}
    L(f) = \sum_{i=1}^N L(y_i,f(x_i)),
\end{equation}

portanto, queremos minimizar $L(f)$ em função de $f$, onde $f$ é descrita na equação \ref{eq:tree_boost}. Logo, sendo $\boldsymbol{f}$ as funções que aproximam $f(x_i)$ em cada ponto $x_i$ de $N$, fazemos
\begin{equation}
\label{eq:step_boost}
\hat{\boldsymbol{f}} = \underset{\boldsymbol{f}}{\text{arg min }}L(\boldsymbol{f}).
\end{equation}

Usamos então o método do gradiente para otimizar a equação \ref{eq:step_boost}, sendo $\rho$ a taxa de aprendizado atualizamos
\begin{equation}
    \boldsymbol{f}_m = \boldsymbol{f}_{m-1} - \rho_m \boldsymbol{g}_m,
\end{equation}
onde os componentes do gradiente $\boldsymbol{g}_m$ são dados por
\begin{equation}
    g_{im} = \left[ \frac{\partial L(y_i,f(x_i))}{\partial
                f(x_i)} \right]_{f(x_i)=f_{m-1}(x_i)}.
\end{equation}

A implementação detalhada deste algoritmo está apresentada pelo pseudo-código do Algoritmo \ref{algo:gbm}.

\begin{algorithm}[ht]
    \SetKwInput{KwInput}{Input}
    \SetKwInput{KwOutput}{Output}
    \KwData{Conjunto de dados D com atributos p.}
    \KwInput{M - Número de estimadores a serem construídos.}
    \KwOutput{Classificador - $f_M(x)$.}
    \begin{enumerate}
        \item Construa $f_0(x) = \textit{arg min}_\gamma \sum_{i=1}^N$
        \item Para $m=1$ até $M$.
        \begin{enumerate}
            \item Para $i=1,2,..,N$ calcule
                \[ r_{im} = - \left[ \frac{\partial L(y_i,f(x_i))}{\partial
                f(x_i)} \right]_{f=f_{m-1}}\]
            \item obtenha a árvore de regressão para os $r_{im}$ dada as
                regiões terminais $R_{jm}, j=1,2,..,J_m$.
            \item Para $j=1,2,..,J_m$ calcule
                \[\gamma_{jm} = \sum_{x_i \in R_{jm}}
                L(y_i,f_{m-1}(x_i)+\gamma)\]
            \item Atualize $f_m(x) = f_{m-1}(x) +
                \sum_{j=1}^{J_m} \gamma_{jm}I(x \in R_{jm})$.
        \end{enumerate}
        \item Retorne $\hat{f}(x) = f_M(x)$.
    \end{enumerate}
    \caption{Máquina de Reforço do Gradiente}
    \label{algo:gbm}
\end{algorithm}


\subsection{Máquina de Vetores de Suporte (SVM)}
Máquinas de vetores de suporte são construídas em cima de duas ideias muito
elegantes do ponto de vista teórico, classificadores de máxima margem e
projeções vetoriais. Classificadores de máxima margem obtém um hiperplano de
solução única tal que a margem entre esse hiperplano e os pontos de duas
classes, se linearmente separáveis, seja máximo, resultando em um hiperplano
com garantias de uma boa generalização \cite{vapnik2013nature}.

\begin{figure}[ht]
   \centering
    \begin{subfigure}{.48\textwidth}
        \centering
        \def\svgwidth{\linewidth}
        \incfig{maxmargin}
    \end{subfigure}
     \hfill
    \begin{subfigure}{.48\textwidth}
        \centering
        \def\svgwidth{\linewidth}
        \incfig{svm}
    \end{subfigure}
    \caption{Máquina de vetores de suporte. A direita temos exemplos de dados
    que são linearmente separáveis logo é possível margens rigidas e a direita
    dados não-linearmente separáveis onde são necessárias margens permissivas.
    Os pontos $\xi_i$ são aqueles que estão do lado errado do plano.}
    \label{fig:svm}
\end{figure}

Porém, uma vasta gama problemas não apresenta uma separação linear entre as
classes, sendo necessárias duas abordagens generalizar esse algoritmo, projetar
os dados em uma dimensão em que sejam linearmente separaveis, possívelmente uma
dimensão infinita através do ``truque de núcleo'' (\textit{kernel trick}), e
também tornar as margens menos restritas para se adaptarem a ruídos nos dados.
Inicialmente definimos o hiperplano como

\begin{equation}
    \label{eq:svm_func}
    x^T\beta + \beta_0 = 0
\end{equation}

Sendo $\beta$ o vetor unitário, isto é $\Vert\beta\Vert = 1$ e a regra de
classificação é dada por

\begin{equation}
    \label{eq:svm_sign}
    G(x) = \text{sign}(x^T\beta + \beta_0)
\end{equation}

Para obter o hiperplano de máxima margem otimizamos $\beta$ restringindo o
critério de otimização de tal forma que suavize para os pontos $\xi_i$, logo

\begin{equation}
    \underset{\beta,\beta_0}{\text{min}} \frac{1}{2}\Vert\beta\Vert^2 +
    C\sum_{i=1}^{N}\xi_i \hspace{1em} \text{subject to } \xi_i \geq 0,
    y_i(x_i^T\beta+\beta_0) \geq 1-\xi_i \forall i
\end{equation}

Onde $C$ é um hiperparametro definido \textit{a priori} que ajusta a rigidez
das margens quanto a pontos erroneamente classificados. Essa operação tem por
forma primal de Lagrange

\begin{equation}
    \label{eq:lag_svm}
    L_p = \frac{1}{2}\Vert\beta\Vert^2 + C\sum_{i=1}^{N}\xi_i -
    \sum_{i=1}^{N}\alpha_i [y_i(x_i^T\beta+\beta_0) - (1-\xi_i)] -
    \sum_{i=1}^{N}\mu_i\xi_i
\end{equation}

Porém como anteriormente discutido, nem todos os problemas podem ser
linearmente separáveis, o que limitaria e muito a aplicabilidade desse
algoritmo, uma alternativa a isso é projetar os dados em uma dimensão em que as
classes sejam separáveis pelo hiperplano, essa projeção é feita por uma função
$h(x)$, for exemplo $h(x) = (x_1^2, x_2^2, x_1^2+x_2^2)$ como mostrado na
Figura \ref{fig:svm_kernel}.

\begin{figure}[ht]
   \centering
    \def\svgwidth{\linewidth}
    \incfig{svm_kernel}
    \caption{Operação de núcleo sobre os dados. A esquerda dados que não são
    linearmente separáveis se transformam em separáveis com a projeção
    demonstrada na figura a direita.}
    \label{fig:svm_kernel}
\end{figure}

Desta forma, rescrevemos a função do hiperplano \ref{eq:svm_func} como

 \begin{equation}
    \label{eq:svm_kernel}
    h(x)^T\beta + \beta_0 = 0
\end{equation}

Pela forma da equação \ref{eq:lag_svm} e \ref{eq:svm_sign} reescrevemos o
o classificador da seguinte forma

\begin{equation}
    G(x) = \text{sign}
    \left(\sum_{i=1}^N \alpha_i y_i \langle h(x),h(x_i)\rangle+\beta_0 \right)
\end{equation}

A literatura costuma apresentar tres escolhas populares para núcleo, que são

\begin{equation}
    \begin{split}
        \text{Polinomial:} &\quad (1+\langle x,x_i\rangle)\\
        \text{Base Radial:} &\quad \text{exp}(-\gamma \Vert x - x_i\Vert^2)\\
        \text{Rede Neural:} &\quad \text{tanh}(k_1\langle x,x_i\rangle+k_2)
    \end{split}
\end{equation}

Devido a elegância teórica desse algoritmo a sua generalização é dada em função
da quantidade de vetores de suporte escolhidos, e embora essa projeção aumente
a dimensionalidade dos dados, no caso do núcleo de base radial para uma
dimensão infinita, ele ainda tem garantias de ter um baixo erro fora dos dados
conhecidos \cite{vapnik2013nature}.

\subsection{``Não existe almoço grátis''}
Vimos a viabilidade e descrevemos o projeto de alguns algoritmos, surge então a
seguinte questão: ``Para um dado problema com características $Z$, qual desses
algoritmos deve ser selecionado?''. Como apresentado pelo teorema do \textit{No
Free Lunch} em \cite{wolpert1997no,wolpert1996lack}, não há uma distinção
formal, \textit{a priori}, entre esses algoritmos que aponte qual é o mais
adequado a um dado problema, logo, métodos experimentais e estatísticos são
aplicados nessa tarefa, como conjuntos de validação, para comparar e selecionar
algoritmos. Porém está abordagem apresenta algumas limitações dada a
insuficiência estatística ou vieses causados pelo método empírico.

Neste trabalho buscamos automatizar e diminuir problemas causados pela seleção
empírica de algoritmos, usando informações \textit{a posteriori} do espaço de
instâncias para essa escolha, essa abordagem também conhecida como
meta-aprendizado.

\section{Meta-Aprendizado}
\label{sec:metalearning}

O problema de seleção de algoritmos foi inicialmente observado por J. R. Rice
(1976) \cite{Rice1976} com o principal objetivo de prever o melhor algoritmo
para resolver um dado problema quando houver mais de um algoritmo que resolva
disponível.
Os componentes desse modelo são: o espaço de instâncias do problema ($P$), que
é composto por conjuntos de dados em Meta-Aprendizado (MtA); o espaço de
instâncias de atributos ($F$), que são os meta-atributos usados para descrever
os conjuntos de dados; o espaço de algoritmos ($A$), que contém um conjunto de
algoritmos de AM que podem ser recomendados; e um espaço de medidas de
avaliação ($Y$), responsável por recuperar as performances dos algoritmos de AM
que resolvem as instâncias dos problemas contidos em $P$.
Usando os conjuntos descritos anteriormente, um sistema de MtA pode criar o
mapeamento de um conjunto de dados $p$ descrimináveis pelos meta-atributos $f$
em um ou mais algoritmos $\alpha$, de tal forma que a recomendação de
algoritmos por sistema tenha uma performance medida por $y$ tolerável, e.g.,
com máximo $y(\alpha(p))$.

K. A. Smith-Miles (2008) \cite{SmithMiles2008} aprimorou esse modelo abstrato
propondo generalizações que podem também ser aplicadas ao problema do projeto
de algoritmos.  Nessa proposta, alguns componentes são adicionados: o conjunto
de algoritmos de MtA; a generalização de regras empíricas ou ranqueamento de
algoritmos; a verificação de resultados empíricos, que podem ser guiados por
uma base teórica ao aprimoramento de algoritmos.

Um componente crucial dos modelos anteriores é a definição do conjunto de
meta-atributos ($F$) usados para descrever propriedades gerais dos conjuntos de
dados. Esses meta-atributos devem ser capaz de prover evidências sobre
performance futuro dos algoritmos em $A$ \cite{Soares2001, Reif2012} e
discriminar, com baixo custo computacional, a performance de um grupo de
algoritmos. Formalmente em \cite{Rivolli2018} essa caracterização é descrita da seguinte forma:
Seja $D \in \mathcal{D}$ um conjunto de dados, $m:D\rightarrow\mathbb{R}^n$ uma medida de caracterização, $\sigma:\mathbb{R}^{n'}\rightarrow\mathbb{R}^n$ uma função de sumarização.
Ambas $m$ e $\sigma$ tem hiperparametros associados, $h_m$ e $h_\sigma$. Logo, um meta-atributo
$f:D\rightarrow\mathbb{R}^n$ para um dado conjunto de dados $D$ é

\begin{equation}
    f\big(D\big) = \sigma\big(m(D,h_m), h_\sigma\big).
\end{equation}

Os principais meta-atributos usados na literatura de MtA podem ser
divididos em cinco grupos: Gerais, Estatísticos, de Teoria da Informação,
Baseados em Modelo e de Landmarkings. Os Gerais podem ser facilmente extraídos dos dados \cite{Reif2014}, com baixo
custo computacional \cite{Reif2012}.
Os meta-atributos estatísticos capturam os indicadores principais sobre
localização e distribuição dos dados, tais como média, desvio padrão,
correlação e curtose.
Meta-atributos de teoria da informação, usualmente medidas de entropia
\cite{Segrera2008}, capturam a quantidade de informação em um (sub)conjunto dos
dados \cite{SmithMiles2008}.
Já os baseados em modelo são propriedades extraídas de modelos de AM,
geralmente AD \cite{Bensusan2000, Peng2002}, induzidos dos dados sob analise
\cite{Reif2014}.
Os meta-atributos de Landmarking usam a performance de algoritmos de
aprendizado simples e rápidos para caracterizar os conjuntos de dados
\cite{SmithMiles2008}.

A definição do conjunto de instâncias de problema ($P$) é outra preocupação,
quando o ideal seria usar um grande número de conjuntos de dados diversos, com
objetivo de induzir um meta-modelo confiável.
Para reduzir o viés dessa escolha, conjuntos de dados de diversos repositórios,
tais como o UCI\footnote{\url{https://archive.ics.uci.edu/ml/index.php}}
\cite{Lichman2013} e o OpenML\footnote{\url{http://www.openml.org/}}
\cite{OpenML2013}, podem ser usados.

O espaço de algoritmos $A$ representa o conjunto de algoritmos candidatos a
serem recomendados no processo de seleção de algoritmos.
Idealmente, esses algoritmos devem também ser suficientemente distintos entre
si e representar toda a região do espaço de algoritmos \cite{Munoz2018}.
Os modelos induzidos pelo algoritmo podem ser avaliados por diferentes medidas,
para tarefas de classificação, a maioria dos estudos usando MtA usam acurácia.
Entretanto, outros indicadores, como o $F_\beta$, AUC e coeficiente Kappa,
também podem ser usados.

Após a extração dos meta-atributos dos conjuntos de dados e a mensuração da
performance do conjunto de algoritmos nesses conjuntos de dados, o próximo
passo é rotular cada meta-exemplo nos meta-dados.
Brazdil et al. (2009) \cite{Brazdil2009} resume as quatro propriedades
principais frequentemente usadas para rotular meta-exemplos em MtA: ($i$)
o algoritmo que apresenta a melhor performance no conjunto de dados (uma tarefa
de classificação); ($ii$) o ranqueamento dos algoritmos de acordo com suas
performances no conjunto de dados (uma tarefa de ranqueamento), onde o
algoritmo com melhor performance está no topo do ranque; ($iii$) o valor de
performance obtido por cada algoritmo individualmente no conjunto de dados (uma
tarefa de regressão) e; ($iv$) a descrição do modelo, que é geralmente baseado
em agrupamentos ou regras de associação.

\section{Fluxos de Dados}

\label{sec:datastreams}
Dados estáticos e bem estruturados não se apresentam como uma boa alternativa a
modelagem em ambientes com massiva interação livre de usuários, para esses
ambientes uma das possíveis abordagens são fluxos de
dados\cite{babcock2002models}.
Embora fluxos de dados sejam observados no tempo, similar a definição de uma
série temporal eles diferem de séries temporais em alguns aspectos, fluxos de
dados não tem uma frequência fixa entre as observações, sendo essa frequência
definida geralmente pela ordem aleatória da geração dos dados que pode ou não
ter uma natureza evolutiva  \cite{gama2007learning}. Outro aspecto importante
ao lidar com desse tipo de dado são as limitações de engenharia, dado que é um
conjunto infinito (não terminável) de dados e que não podem ser lidos
livremente, dado os limites computacionais impostos pela grande quantidade de
dados \cite{babcock2002models}. Por ultimo, acredita-se que fluxos de dados não
tenham dependências temporais, diferentes de séries temporais, porém em artigos
como \cite{read2018concept} é apresentado que não é isso que ocorre no caso de
mudança de conceito.

Essas limitações práticas causam limitações significativa nos métodos e
abordagens que podem ser aplicados na mineração de fluxos de dados, essa que
será tratada nessa seção. Séries temporais (e similarmente, fluxos de dados)
podem ser gerados por dois tipos de distribuições, estacionárias e
não-estacionárias, para a primeira se tem medias e variâncias constantes para
qualquer janela ao longo do tempo, já na segunda, esses dois parâmetros podem
variar em função de fenômenos conhecidos ou desconhecidos por trás do processo
gerador desses dados\cite{read2018concept}. Tais padrões de variações costumam
recorrer em diversas series por isso nomes foram atribuídos a cada
comportamento, são eles, tendência, ciclos, sazonalidade e mudança de conceito
\cite{hyndman2018forecasting,tsymbal2004problem,brockwell2016introduction}.

Tendências e ciclos geralmente descrevem eventos econômicos de crescimento (ou
decrescimento) e oscilações de subida e descida dado por flutuações de curto
prazo, para simplicidade e por esses fenômenos terem uma natureza similar, eles
são agregados em uma única componente e denominados por ``ciclo-tendência'' ou
apenas ``tendência'' \cite{hyndman2018forecasting}.

Com o passar dos anos é esperado um crescimento populacional e naturalmente a
população empregada também irá crescer, a Figura \ref{fig:trend} apresenta a
série temporal do número de pessoas formalmente empregadas nos Estados Unidos,
do ano 1947 a 1962, é observável o efeito da tendência no comportamento da
série temporal já que vemos o crescimento como descrito acima.

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{longley}
    \caption{Exemplo de tendência.}
    \label{fig:trend}
\end{figure}

Padrões sazonais ocorrem quando um fenômeno observado é afetado por fatores
sazonais, por exemplo o período do ano ou a hora do dia, esse necessariamente
de uma frequência fixa conhecida
\cite{hyndman2018forecasting,brockwell2016introduction}. Na Figura
\ref{fig:seasonality}, é apresentado uma série de observações da temperatura
média diária na cidade de Melbourne, Austrália ao longo de 10 anos, essa séria
apresenta um padrão de sazonalidade, sendo a temperatura da terra afetada pelo
ciclos solar, as estações do ano, é possível observar a periodicidade do
aumento e diminuição da temperatura relacionado a isso.

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{temperature}
    \caption{Exemplo de sazonalidade.}
    \label{fig:seasonality}
\end{figure}



\textcolor{red}{descrever mudança de conceito estatisticamente, detalhar}

% %http://www.dfki.de/lwa2005/fgml/paper09.pdf mudança de conceito formal nesse paper


% \begin{figure}[ht]
%     \centering
%     \includegraphics[width=\textwidth]{elec}
%     \caption{Exemplo de mudança de conceito.}
%     \label{fig:concept_drift}
% \end{figure}

A maioria das técnicas de AM assumem que os dados são independentes e
identicamente distribuídos (\textit{iid}), mas essas premissas geralmente não
se sustentam em ambientes de fluxos de dados, como apontado por A. Bifet and R.
Gavald\`a (2007) \cite{bifet2007learning}, dado que os dados chegam
interminavelmente e, por isso, podem apresentar dependência temporal e mudanças
de conceito pode ocorrer.  Outro aspecto critico é a imposição de limites
computacionais a esses ambientes, como memória, CPU, e largura de banda
\cite{bifet2010moa, gama2012survey}.  Para resolver esses problemas, diversas
tecnologias foram desenvolvidas. Dentre elas, as mais proeminentes são
mecanismos de esquecimento, testes estatísticos e algoritmos adaptativos.

Mecanismos de esquecimento fazem dados recentes tornarem-se mais relevantes e
dados passados menos, um exemplo são janelas deslizantes
\cite{gaber2005mining}, um método agnóstico de modelo.
Sistemas baseados em testes estatísticos agem monitorando uma métrica
pre-definida, tal como performance preditiva do modelo, e então ``disparam'' um
alarme quando a qualidade dessas métricas está abaixa de algum limiar
tolerável, demandando alguma ação.

Exemplos dessa abordagem são o teste de Page-Hinkley e o \textit{Statistical
Process Control} \cite{gama2010knowledge}.
Baseado nessas duas soluções, o \textit{ADaptive WINdowing} (ADWIN) \cite{bifet2007learning} usa testes estatísticos para definir o tamanho de cada janela, ajustando ao ``tamanho do conceito''.
Entretanto, embora esses métodos serem capazes de alarmar uma redução na performance dos modelos e adaptar o tamanho da janela a isso, não é possível identificar os algoritmos ou modelos que se tornaram mais apropriados ao novo conjunto de dados que está sendo gerado.

Algoritmos de aprendizado adaptativo, como o VFDT \cite{domingos2000mining},
foram inicialmente introduzidos com fluxos de dados em mente, desempenhando aprendizado online e baixo consumo de memoria, mas não conseguiam se adaptar a mudança de conceito, um problema já conhecido na época.
Mais tarde, aprimoramentos foram propostos, como o CVFDT (um aprimoramento direto sobre o VFDT) \cite{hulten2001mining}, o HAT \cite{bifet2009adaptive} e o ARF \cite{gomes2017adaptive}, que podem lidar com variação de conceito aplicando janelas deslizantes sobre o processo de treinamento.
Entretanto, se a mudança for muito abrupta, o espaço de hipótese, fixado a priori do algoritmo (Arvore de Decisão (AD) para a maioria deles) pode não ser mais adequado e as adaptações desejadas não serem atingidas.

\textcolor{red}{Outra alternativa são algoritmos genéticos, como em \cite{kanade2010evolution} e \cite{kang2017visualising} e outros artigos usando meta-learning}
Esses problemas podem ser reduzidos quando se usa detectores de mudança baseado em sistemas de recomendação baseados em MtA, almejando espaços de hipótese como tarefas de aprendizado \cite{rossi2014metastream}.

% \section{Meta-atributos}
% \label{sec:meta-atributos}
% O objetivo do meta-aprendizado é relacionar a performance do agente aprendiz
% com as características dos dados\cite{brazdil2008metalearning}, chamadas
% meta-atributos. Tais características devem ser explicativas sobre a performance
% relativa para que o meta-aprendiz possa efetivamente aprender performance relativa
% a elas. Em \cite{brazdil2008metalearning} são citados pontos que devem ser
% considerados na concepção de meta-atributos:
% \begin{itemize}
%     \item \textbf{Poder Discriminativo}, sendo o meta-aprendiz designado a
%     diferenciar os aprendizes de nível base, os meta-atributos devem poder
%     explicativo para desempenhar esta tarefa.
%     \item \textbf{Complexidade Computacional}, se o custo computacional de obter
%     os meta-atributos for maior do que de avaliar todo o espaço de hipótese, não
%     compensa utilizar do meta-aprendizado.
%     \item \textbf{Dimensionalidade}, a dimensão dos meta-atributos não pode ser
%     maior que a quantidade de meta-dados ou ocorrerá sobre-ajuste aos dados.
% \end{itemize}
\textcolor{red}{falar do \cite{talagala2018meta}}

